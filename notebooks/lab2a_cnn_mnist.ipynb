{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab2a_Keras_CNN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amX102GVM0OO"
      },
      "source": [
        "Introduction to Convolutional Neural Networks (CNNs)\n",
        "=========\n",
        "\n",
        "Convolutional neural networks (CNNs, aka ConvNets) exploit the spatial information in input stimuli (e.g. 2D images), instead of using input as a lineral vector of numbers.\n",
        "The CNN architecture is inspired by the topology and function of the visual cortex, in which a hierarchy of layers process visual information in an incremental way. E.g. our brain starts from the recognition of on/off pixels, then their grouping into lines, their subsequent combination is simple 2D shapes, up to the recognition of compelx 3D shapes and objects.\n",
        "\n",
        "Specifically, a deep CNN consists of many stacked layers. There are two main types of layers, convolutional and pooling, which typically alternate. \n",
        "\n",
        "An important principle of the convolution layer is that of receptive fields. That is, a 2D subregion (submatrix) of the input image (matrix) is connected to one hidden unit, and this subregion corresponds to the receptive field of this hidden unit. The next hidden unit will have a receptive field from the adjactent (or partially overlapping) subregion of the input matrix. This corresponds to the convolution mechanism. In Keras, the size of each submatrix is called __kernel size__. This is one of the key hyperparameters in CNNs. \n",
        "\n",
        "For example, with an MNIST image of 28x28 pixels, and a receptive field (kernel size) of 5x5 pixles feeding into a single hidden unit, and with a shifting of the subregion by 1 pixel (stride length), the next hidden layer will constitute a (feature) map of 23x23 units.\n",
        "\n",
        "Each input matrix or hidden layer can be connected to multiple __feature maps__ in the next hidden layer. All the neurons in the hidden layer of each feature map will share the same weights and biases. This way each feature map layer learns a set of position-independent latent features derived from the image. \n",
        "\n",
        "The pooling (aka sub-sampling) mechanism is used to group (pool) together the output of a fetaure map. This can be done with Max Pooling (where the highest value of the pooling units is used in the next hidden unit) or Average Pooling (where the average value of the subregion activations is computed). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLCI1BC7M0OW"
      },
      "source": [
        "**LeNet for MNIST**\n",
        "\n",
        "One of the pioneering works in Deep Learning and CNN was the original model by Yann LeCun and colleagues (see: Y. LeCun and Y. Bengio, 1995, \"Convolutional Networks for Images, Speech, and Time-Series\". Brain theory neural networks, vol. 3361). This is referred to as the LeNet. This LeNet was for example used on the MNIST problem, to show the robustness to simple geometric transformations and distortion of the handwritten code. Here we will look at the Keras code for the LeNet on MNIST dataset.\n",
        "\n",
        "In this exercise we will implemente the code for the specific LeNet network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiX1ak-IM0Ob"
      },
      "source": [
        "**2D Convolution module**\n",
        "\n",
        "The definition of a convolution module has this format:\n",
        "\n",
        "__keras.layers.convolutional.Conv2D(filters, kernel_size, padding='valid')__\n",
        "\n",
        "\n",
        "It requires the following parameters:\n",
        "- __filters__, the number of convolution kernels to use (i.e. dimensionality of the output)\n",
        "- __kernel_size__, with two integers specifying the width and height of the 2D convolution window (or a single integer to specify the same value for all spatial dimensions)\n",
        "- __padding__, with __'same'__ is used where the area around the input is padded with zeros, resulting in an output with the same size as the input. Instead, __'valid'__ is used when the convolution is only computed where the input and the filter fully overlap, resulting in a smaller output size.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn3HyO6SM0Of"
      },
      "source": [
        "**2D Pooling module**\n",
        "\n",
        "The definition of a pooling module has this format:\n",
        "\n",
        "__keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))__\n",
        "\n",
        "\n",
        "This uses two main parameters:\n",
        "- __pool_size__, where a tuple of integers represent the verical and horizontal downscaling factors (e.g. (2, 2) will halve the image in each dimension)\n",
        "- __strides__, with the two integers for the stride/dimensions used for the max/average pooling processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_myY0ilM0Oi"
      },
      "source": [
        "**Initialisation for the program**\n",
        "\n",
        "The program starts with the importing of typical Keras and other Python service modules. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkWmAbcnmGdj"
      },
      "source": [
        "# Run this cell ONLY if using Google Colab\n",
        "\n",
        "%tensorflow_version 1.13  # use previous version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aEl9JNghM0Oq",
        "outputId": "ef00e231-79d7-48f6-9e67-a9d574a21559"
      },
      "source": [
        "# importing of modules for LeNet CNN \n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "\n",
        "# importing of service libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Libraries imported.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Libraries imported.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T2Gbw9BM0O5"
      },
      "source": [
        "The following variable definitions are needed for the network and training parameters, and the image size.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iAm6KH81M0O7",
        "outputId": "408a5bf7-a276-4ac2-a695-8b8c5c302ef6"
      },
      "source": [
        "# seed for reproducibility\n",
        "np.random.seed(1671)  \n",
        "\n",
        "# network and training parameters\n",
        "N_EPOCH = 20 # later use 20 for better results\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "OPTIMIZER = Adam()\n",
        "VALIDATION_SPLIT=0.2\n",
        "\n",
        "IMG_ROWS, IMG_COLS = 28, 28 # input  dimensions of each MNIST image\n",
        "N_CLASSES = 10  # number of outputs = number of digits\n",
        "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
        "\n",
        "print('Main variables initialised.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Main variables initialised.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWSa30VZM0PD"
      },
      "source": [
        "**LeNet class definition for the CNN model**\n",
        "\n",
        "This code defines the class LeNet for the building of the CNN model.\n",
        "\n",
        "It has a first convolution module followed by a pooling layer. This convolution layer (with ReLu activation function) has 20 filters, each with a kernel size of 5x5. The output dimension is the same as the input imge of 28x28 units (because we use the __same__ padding parameter. The pooling layers uses a regioin of 2x2, with max pooling values.\n",
        "\n",
        "Another comvolution layer of 50 filters is then pooled.\n",
        "\n",
        "This layer is then flattened into a one-dimensional layer, followed by a dense layer of 500 units.\n",
        "\n",
        "Finally, a softmax dense layer in output classifies the images into the 10 number categories.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SGhOzs6lM0PG",
        "outputId": "e477992b-58d4-484b-9fe6-0f7e95de0bfd"
      },
      "source": [
        "#define the convnet \n",
        "class LeNet:\n",
        "\t@staticmethod\n",
        "\tdef build(input_shape, classes):\n",
        "\t\tmodel = Sequential()\n",
        "        \n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(Conv2D(20, kernel_size=5, padding=\"same\", input_shape=input_shape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "        \n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "        \n",
        "\t\t# Flatten => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(500))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        " \n",
        "\t\t# a softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\treturn model\n",
        "\n",
        "print('LeNet class defined.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet class defined.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5i-g_HtM0PV"
      },
      "source": [
        "**MNIST data loading and processing**\n",
        "\n",
        "This code loads the MNIST dataset, as in the previous labs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "Jum1Is0uM0PY",
        "outputId": "48eddaee-d67c-49d3-bd90-8bc1b436eed1"
      },
      "source": [
        "# data: shuffled and split between train and test sets\n",
        "(input_X_train, output_y_train), (input_X_test, output_y_test) = mnist.load_data()\n",
        "# K.set_image_dim_ordering(\"th\")\n",
        "\n",
        "# consider them as float and normalize\n",
        "input_X_train = input_X_train.astype('float32')\n",
        "input_X_test = input_X_test.astype('float32')\n",
        "input_X_train /= 255 \n",
        "input_X_test /= 255  \n",
        "\n",
        "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
        "input_X_train = input_X_train[:, np.newaxis, :, :]\n",
        "input_X_test = input_X_test[:, np.newaxis, :, :]\n",
        "\n",
        "print(input_X_train.shape[0], 'train samples')\n",
        "print(input_X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "output_y_train = np_utils.to_categorical(output_y_train, N_CLASSES)\n",
        "output_y_test = np_utils.to_categorical(output_y_test, N_CLASSES)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be35OGl_M0Pe"
      },
      "source": [
        "**CNN initialisation and compilation**\n",
        "\n",
        "This initialises the model using the LeNet function, and then compiles the network and shows its summary. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nk03ubuUM0Pg",
        "outputId": "c011911a-28d5-4f01-da44-e0a52e5f08de"
      },
      "source": [
        "# initialize the optimizer and compile the model\n",
        "model = LeNet.build(input_shape=INPUT_SHAPE, classes=N_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 1, 28, 20)         14020     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1, 28, 20)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 14, 50)         12550     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1, 14, 50)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 7, 25)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 175)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               88000     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 119,580\n",
            "Trainable params: 119,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/cangela/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/Users/cangela/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUHKMyhnM0Pq"
      },
      "source": [
        "**Training of the CNN**\n",
        "\n",
        "This line of code trains the model, saving the metrics data in the history variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "AL9IqEmdM0Pt",
        "outputId": "e9343c0e-5bb1-4230-cc27-e1ffdb3d1717"
      },
      "source": [
        "# training/fitting of the LeNet model\n",
        "\n",
        "# let's reduce the number of epoch to 3, for a faster test of the checkpoint utility. Then revert to N_EPOCH = 20\n",
        "#N_EPOCH = 3\n",
        "\n",
        "history = model.fit(input_X_train, output_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.4240 - accuracy: 0.8792 - val_loss: 0.1462 - val_accuracy: 0.9572\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 13s 271us/step - loss: 0.1198 - accuracy: 0.9637 - val_loss: 0.1055 - val_accuracy: 0.9672\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 16s 341us/step - loss: 0.0868 - accuracy: 0.9731 - val_loss: 0.0855 - val_accuracy: 0.9734\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 14s 302us/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 0.0710 - val_accuracy: 0.9790\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 16s 340us/step - loss: 0.0586 - accuracy: 0.9821 - val_loss: 0.0727 - val_accuracy: 0.9775\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0678 - val_accuracy: 0.9791\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 15s 321us/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0664 - val_accuracy: 0.9804\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 15s 309us/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.0630 - val_accuracy: 0.9814\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 19s 395us/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.0535 - val_accuracy: 0.9837\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 16s 325us/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.0591 - val_accuracy: 0.9833\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.0621 - val_accuracy: 0.9830\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 13s 280us/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0610 - val_accuracy: 0.9831\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 19s 393us/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0573 - val_accuracy: 0.9847\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0573 - val_accuracy: 0.9843\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 16s 334us/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0589 - val_accuracy: 0.9849\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0617 - val_accuracy: 0.9836\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 14s 294us/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0606 - val_accuracy: 0.9835\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 14s 290us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0589 - val_accuracy: 0.9854\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 14s 292us/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0679 - val_accuracy: 0.9834\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 13s 273us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0661 - val_accuracy: 0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAAvUJJ3M0P3"
      },
      "source": [
        "**Analysis of the training results**\n",
        "\n",
        "This generates the test scores by evaluating the trained network with the test dataset.\n",
        "\n",
        "It also plots the accuracy and loss values along the training timescale.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "Uc5-uwhMM0P4",
        "outputId": "00ae1c0d-019d-4fd1-ed29-c5f6e7c4e48f"
      },
      "source": [
        "score = model.evaluate(input_X_test, output_y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 130us/step\n",
            "\n",
            "Test score/loss: 0.05378444789740763\n",
            "Test accuracy: 0.9868000149726868\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcVZn/8c/T+96ddHf2FUgwAUKAEEBAUAYk7IvDrigzxo0ZnZ84gDOCwyzojPrDcUHRiYDIZlxgNLIK8kPWBELYSUBCOl1JOul09Vq91fP7497uVHeqO0WS6u5Ufd+vV73q3nvurXqq0rlPnXPuOdfcHRERkcFyRjsAEREZm5QgREQkKSUIERFJSglCRESSUoIQEZGklCBERCQpJQgRwMxuNbN/S3Hfd83sr9Idk8hoU4IQEZGklCBEMoiZ5Y12DJI5lCBknxE27XzFzNaYWZuZ/Y+ZTTSzP5hZi5k9YmbjEvY/y8xeNbMmM3vczOYllB1mZi+Ex90DFA16rzPMbHV47FNmtiDFGE83sxfNrNnMNpjZ1weVHxe+XlNY/slwe7GZfdvM1ptZ1MyeDLedaGZ1Sb6HvwqXv25my83sDjNrBj5pZovN7OnwPSJm9n0zK0g4/iAze9jMGs1ss5l91cwmmVm7mVUn7HeEmTWYWX4qn10yjxKE7GvOB04G5gJnAn8AvgrUEPw9/z2Amc0F7gK+BNQCK4D/NbOC8GT5W+DnwHjgl+HrEh57OLAM+AxQDfwYuN/MClOIrw34BFAFnA58zszOCV93Rhjv98KYFgKrw+O+BRwBfDCM6R+BeIrfydnA8vA9fwH0Av8QfifHACcBnw9jKAceAR4ApgAHAI+6+ybgceCChNe9DLjb3btTjEMyjBKE7Gu+5+6b3X0j8P+AZ939RXfvBH4DHBbudyHwe3d/ODzBfQsoJjgBHw3kAze5e7e7LweeT3iPTwM/dvdn3b3X3W8DOsPjhuXuj7v7y+4ed/c1BEnqhLD4UuARd78rfN9t7r7azHKAK4AvuvvG8D2fCj9TKp5299+G79nh7qvc/Rl373H3dwkSXF8MZwCb3P3b7h5z9xZ3fzYsu40gKWBmucDFBElUspQShOxrNicsdyRZLwuXpwDr+wrcPQ5sAKaGZRt94EyV6xOWZwJfDptomsysCZgeHjcsMzvKzB4Lm2aiwGcJfskTvsbbSQ6rIWjiSlaWig2DYphrZr8zs01hs9N/pBADwH3AfDPbj6CWFnX353YzJskAShCSqeoJTvQAmJkRnBw3AhFgaritz4yE5Q3Av7t7VcKjxN3vSuF97wTuB6a7eyXwI6DvfTYA+yc5ZisQG6KsDShJ+By5BM1TiQZPyXwz8AYwx90rCJrgdhUD7h4D7iWo6Xwc1R6ynhKEZKp7gdPN7KSwk/XLBM1ETwFPAz3A35tZnpmdByxOOPYnwGfD2oCZWWnY+VyewvuWA43uHjOzxcAlCWW/AP7KzC4I37fazBaGtZtlwHfMbIqZ5ZrZMWGfx1tAUfj++cA/A7vqCykHmoFWM/sA8LmEst8Bk8zsS2ZWaGblZnZUQvntwCeBs4A7Uvi8ksGUICQjufubBO3p3yP4hX4mcKa7d7l7F3AewYlwO0F/xa8Tjl1J0A/x/bB8XbhvKj4P3GBmLcB1BImq73XfA04jSFaNBB3Uh4bFVwEvE/SFNALfBHLcPRq+5k8Jaj9twICrmpK4iiAxtRAku3sSYmghaD46E9gErAU+nFD+Z4LO8RfC/gvJYqYbBolIIjP7I3Cnu/90tGOR0aUEISL9zOxI4GGCPpSW0Y5HRpeamEQEADO7jWCMxJeUHARUgxARkSGoBiEiIkmlbWIvM1tGMGpzi7sfnKTcgO8SXNXRDnzS3V8Iyy4nuJwP4N/CkazDqqmp8VmzZu2l6EVEssOqVau2uvvgsTVAGhMEcCvBZYK3D1G+BJgTPo4iGNxzlJmNB64HFhEMAFplZve7+/bh3mzWrFmsXLlyL4UuIpIdzGz9UGVpa2Jy9ycIruceytnA7R54Bqgys8nAR4GH3b0xTAoPA6emK04REUluNPsgpjJwDpm6cNtQ23diZkvNbKWZrWxoaEhboCIi2Wg0E4Ql2ebDbN95o/st7r7I3RfV1iZtQhMRkd00mnefqiOYPK3PNIIJ1uqAEwdtf3x33qC7u5u6ujpisdhuhrjvKCoqYtq0aeTn694uIrJ3jGaCuB+40szuJuikjrp7xMweBP7DdtwZ7BTg2t15g7q6OsrLy5k1axYDJ+7MLO7Otm3bqKurY/bs2aMdjohkiHRe5noXQU2gJrxl4vUEN2nB3X9EcIev0wgmQmsHPhWWNZrZv7LjBi43uPtwnd1DisViGZ8cAMyM6upq1A8jIntT2hKEu1+8i3IHvjBE2TKC6Y/3WKYnhz7Z8jlFZOSMZhOTiEjWcHc6untp7eyhNdZDW2cvLZ3dtHX20tnTS2/cibvTG4d43Ol1pzfuePjc6wO3x+NO3KHXnUkVRVxy1IxdB/E+KUGkWVNTE3feeSef//zn39dxp512GnfeeSdVVVVpikxEdkdPb5wtLZ1EojE2N8eIRGM0tXfREuuhrbMnSADhoy1MBi3hcjxNU98dNqNKCWJf1NTUxA9/+MOdEkRvby+5ublDHrdixYp0hyYig3R09bKpOcamaIxNzR1sinayKdoxIBlsbe3c6URvBmWFeZQX5lFamEdZUR5lhXlMqigK1gvzKC/K61/ue5SG2wvzcsjJMXLNyM0xcnKMHINcs/7t/dtyjJxwv1wzzNLXxKwEkWbXXHMNb7/9NgsXLiQ/P5+ysjImT57M6tWree211zjnnHPYsGEDsViML37xiyxduhTYMXVIa2srS5Ys4bjjjuOpp55i6tSp3HfffRQXF4/yJxMZPe5OZ0+cWHcvHd29xLrjtHf1BOtdcTr6tnf19i+3d/WG5b07lTe2dbGpOUZTe/dO71VelMfkyiImVRZz4KRyJlUWM6miiMmVRUwMn6tK8jOyHzBrEsS//O+rvFbfvFdfc/6UCq4/86Bh9/nGN77BK6+8wurVq3n88cc5/fTTeeWVV/ovR122bBnjx4+no6ODI488kvPPP5/q6uoBr7F27VruuusufvKTn3DBBRfwq1/9issuu2yvfhaRVDW1d7F+WzvrG9t5b1sb7zW209bVS44Fv3CD54TlnIHbrO9XclhuZvTG4/0n+o7uXjrDE3hHV7At1t07IBnEenrZnTsVFOXnUJyfS0lBXrBckEtxfi7TxpVw5KzxTKos2nHyD5dLC7PmNLmT7P3ko2Tx4sUDxir893//N7/5zW8A2LBhA2vXrt0pQcyePZuFCxcCcMQRR/Duu++OWLySfeJxJ9IcY/22NjY0tickg3bWb2ujOdYzYP8J5YWUF+XhTtDJ6k48HvzK7+tE7VuO93e8BsvxcN+8XKMoPzhZF4Yn8aLwRD6+NIeicD3YHpYX5FKU17dfWB6e8IvzcykuyKG4IK9/va8ZR1KXNQliV7/0R0ppaWn/8uOPP84jjzzC008/TUlJCSeeeGLSUd+FhYX9y7m5uXR0dIxIrJJZeuNOtKOb7e1dNLV30di2Y7m+KUgI6xvbqWvsoKs33n9cXo4xbVwxM6pLWTi9ipnVJcwYX8LM6lJmjC+huGDovjTZt2VNghgt5eXltLQkv3tjNBpl3LhxlJSU8MYbb/DMM8+McHSyL4t194adqTG2tXb1n+y3t3ezvS1Y397e3b+tOdY9ZLNMaUEuM6pLmTuhnJPnTWRGdQkzx5cys7qEyZVF5OXq3mLZSAkizaqrqzn22GM5+OCDKS4uZuLEif1lp556Kj/60Y9YsGABBx54IEcfffQoRipjhbvT0tkTnPzDRyRMBIlX1GxP0qEKUFKQy7iSAqpK8hlfWsD08SWMK8mnqqSAcSX5jCspYFzpjuWqknzKCvMyspNV9kzG3JN60aJFPviGQa+//jrz5s0bpYhGXrZ93n2Nu9Mc62FraycNLcGjb3lzcyebmsOTfzRGW1fvTsdXlxYwqXLg1TMTK4qYVFlEbXlh/8m+ME9NPpI6M1vl7ouSlakGIbIH3J32rl62tnYOOPE3tHYlLHeyNXzu6onv9Bp5OcaE8kImVRbxgUnlnDh3ApMqC5lUWRxcXllRxISKQp34ZcQpQYiE+k72jWH7fWNbF03t3f3r29u72N6283pih24fM6guLaSmrIDa8kL2ry2ltqyQ2vLgUVO247mqOF9X18iYpAQhWSUedzY2dfDW5hbe2tzK2s0trGtoDdr0hzjZA+QY/W34fe36h06r6m/Lr+47+ZcVUlNewPiSAnXsyj5PCUIyUl8iWLslSARvbW5h3ZZW1m1ppT2hfX9SRRFzJpYxb1LFjo7b0uAEP6406MQdX1pARZF+5Uv2UYKQfVpv3Klv6mDdliAJrN0S1ArWDkoEEysKmTuxnAuPnM7cieXMnVjGARPKqSzWHfhEhqIEIWOeu9PQ2sm7W9v5y9ZW3tnaxrtb2/jL1jbe3dY+oON3QnmQCC5YtCMRzJlQTmWJEoHI+6UEkWa7O903wE033cTSpUspKSlJQ2RjT7Sju//En5gE/rK1jdbOHdM7FOTmMKO6hNk1pXz4wAnMqinlgAllzJlQRlVJwSh+ApHMogSRZkNN952Km266icsuuyzjEoS7Ux+N8dKGJlaHj7e3tLKtrat/HzOYNq6Y2TVlHDFzHLOqS5hdW8Z+NaVMqSomV/0BImmnBJFmidN9n3zyyUyYMIF7772Xzs5Ozj33XP7lX/6FtrY2LrjgAurq6ujt7eVrX/samzdvpr6+ng9/+MPU1NTw2GOPjfZH2W0tsW7W1EVZvaGJF99r4qW6JhpaOoGgNjB/SgUnz5/I7JpSZteUsl9tKdPHl+i6fxm74nHY/heofzF4mMHUI4JH5fRgfSS0N0LkJejthrmn7PWXz54E8YdrYNPLe/c1Jx0CS74x7C6J030/9NBDLF++nOeeew5356yzzuKJJ56goaGBKVOm8Pvf/x4I5miqrKzkO9/5Do899hg1NTV7N+406u6N8+amlv6aweoNTbzd0No/B9B+NaUcf0ANh06vYuH0KuZNrqAgT5eDjjh3aN0Mm1+FLa9DTwfkl0JBSficuFwSrPeXlwx/AuzphFgzxKLBozO6YzkWHVgWi0Jnc/D64/cb+KiaCXljoMnQHba/uyMZ1L8IkTXB5wLIDSfT7A1+9FBauyNZTD0cphwOJeP3PIaWTUEy2LQmeI68BNENQfnEg5Ug9nUPPfQQDz30EIcddhgAra2trF27luOPP56rrrqKq6++mjPOOIPjjz9+lCNNjbvzXmN7f+3gpQ1NvLwxSmfYaTy+tICF06s469ApLJxexaHTqtRZPBo6W4MksOVV2PwabHktSAwdjbv/monJoqAU4j07Tv49u5ht2HKgqBIKK4Lnokpoa4D3noWuloH7VU7bOXGM3w/GzYL8NNw0yz046SYmg/rVEGsKynMLgpPxIefDlMOCR+0HguO2vAobV8HGF4Lntx4Ewl9G4/eDqYt2JI5Jh0B+0dAxbH9352TQ1tD3xUD1ATB9MSz+NExaAJMP3fvfBdmUIHbxS38kuDvXXnstn/nMZ3YqW7VqFStWrODaa6/llFNO4brrrhuFCIfm7kSiMdbURVlTFySCNXVRoh3BhHGFeTkcPLWSS4+aycIZVRw2vYpp44rH7gRwXW2w4TlY/2d475lgvSD85dx30ns/y/klwX/4vGLIHaX/Vr090Ph2WCt4LUwGrwYnmz75pTBhHsw7AyYcBBPnB8+F5dDdFnwPXe3hcnuw3rfcHa53te1Y7nvOyQtP9n0n/aqdk0BfeUFZ8hqIO7Rvg8Z3dn68+hvo2D5w/4qpYcKYDcXjISc3SCqWA9a3bMHzgLK+ctuxHq2DyOogIbRvC14/Jw8mzIf5Z+9IBhPmD12r6dvnyHA91hy83sZVwePdJ+Hle3e89sSDdySMnLyEZJBQO8nJg9p5MOeUIAlMWgCTDg7+vUZA9iSIUZI43fdHP/pRvva1r3HppZdSVlbGxo0byc/Pp6enh/Hjx3PZZZdRVlbGrbfeOuDY0Whiamjp5OWNTby0IdqfDLa2BlXovBxj7sRyTjtkEodMrWLBtEoOnFRO/lgeOdzZEvxCXf8kvPtnqH8h+NVruTB5QXCC6W6H5vqEE187dLWC7zxx3rBy8oJE0Zcw8osgryj4xTvUs+WAxyHeGzz3P/rWfejyeByi70HDWzuaOSw3+JU55TBYeFmYCOYHzTY5Q/w75RVA8bg9+573hBmU1gSP6Yt3Lm9vDNr9G/8yMHm8+Yeg9pL4vbzv984NEueBSxKSwUFD/8pPRVEF7HdC8OjTXL+jhrFxFbz8S1j5P0FZXtGO2klfMpgwf89i2ENKEGmWON33kiVLuOSSSzjmmGMAKCsr44477mDdunV85StfIScnh/z8fG6++WYAli5dypIlS5g8eXJaO6mjHd2sqWvaUTuoi1IfDW5cZAZzJpRxwtxaFkyrZMG0SuZNrqAof4x3IHc0BTWDvoQQeSk4mebkBW3CH/w7mHkczDhq+F9j7tDbNfDX8uDlrjboiUF3R2rPHdvD9VjQHNMdAzzhF++gX7s5g34NDy63HCifBPuduKNWUHPgqJ5Y0qJkfPCYesTw+7nvSKgDkmw8IckOKi+qCprM0q1iSvCYd0awHo/DtnXBj5WauaNX+xyCpvvOIO/387743nZuf3o9v18T6Z+DaHZNKYdMrQyTQRUHTanYN+7J294I7z0dJIP1TwYXJHg8aDOeughmHQszjw1+mRaU7vr1RLLEqE33bWanAt8FcoGfuvs3BpXPBJYBtUAjcJm714Vl/wmcDuQADwNf9EzJZqOos6eX36+JcNtT7/JSXZSywjwuOWoGJ8+fyMFTK8fm1BPxXmjdAi310ByBlkhQVe97bt4I294GPKimTzsSPvSPQVKYdmR6OjNFskDaEoSZ5QI/AE4G6oDnzex+d38tYbdvAbe7+21m9hHgRuDjZvZB4FhgQbjfk8AJwOPpijfTRaId/OKZ97jruffY1tbF/rWl3HD2QZx3+DTKRrOG0NsNTe8FJ/nmSEISCJ+b64PLMQf3A+TkQdkkqJgctNMuuChICFOPgLzC5O8lIu9LOs8Mi4F17v4OgJndDZwNJCaI+cA/hMuPAb8Nlx0oAgoAA/KBzbsThLuP3Stp9qJklSt357m/NHL70+t54NVNxN056QMTuPyDszjugJqR+156OoMksO3tna9OaXpv55N/YQWUTw5O/vudGDyXTw7abssnB1evlNYEbfMikjbpTBBTgQ0J63XAUYP2eQk4n6AZ6lyg3Myq3f1pM3sMiBAkiO+7++uD38DMlgJLAWbMmLFTAEVFRWzbto3q6uqMThLuzrZt2ygqCjolO7p6uW/1Rm57ej2vR5qpLM7nb46bzcePnsn08WnqiOvuCC6nTHaJYrRu4JUlhRXB5YlTDoODzw8uU6ycviMBFJalJ0YReV/SmSCSnZEH/8y9Cvi+mX0SeALYCPSY2QHAPGBauN/DZvYhd39iwIu53wLcAkEn9eA3mzZtGnV1dTQ0NAwuyhy9XRCLUtS5lYrmN/jtk6Xc+XYRa2K1zJpUw43nHcI5C6dSXLCXfm3HmmHrW8HAq4Y3wuc3oblu4H7F44IkMP0oOPTi8Hr1/YPnkvEjNxWBiOy2dCaIOmB6wvo0oD5xB3evB84DMLMy4Hx3j4Y1g2fcvTUs+wNwNEESSVl+fj6zZ8/e/U8wlrU3wh//DV/1M3oKKmnsLaGqu55zzDkH8CIDpmNvzYXGA6FmDtQeGFz+WFq969fvbAmuq294PSEZvDEwEeQVBa8784PBc9+gpXGz93xqAREZdelMEM8Dc8xsNkHN4CLgksQdzKwGaHT3OHAtwRVNAO8BnzazGwlqIicAN6Ux1n1HvBdW3Qp//Fc81swfis/kmsYzyCsdx2VHT+CyOb1M6FyPbV0b/LLf+mZw6Wfi9AfF48NkMSdIGNX7Bwmn4fUgCTS8sWOOFwjmmqmdCzOPCaYVmDAveB43S/0AIhksbQnC3XvM7ErgQYLLXJe5+6tmdgOw0t3vB04EbjQzJ6gdfCE8fDnwEeBlgmapB9z9f9MV6z7jvWdgxVdg0xreLFrA38cuYVvuAfyfMw/gosUzEgavHT7wuHg8OOFvXRskjK1vBbWDN34P7bfv2C+3MBisM+NoqL08GOI/YZ4SgUiWyuiBchmjZRM8fB2suYftebV8reMi/pR3HJ85YX8+dezsPRvI1rYtmL+neHyQCMbYSE4RSa9RGygne6inC569mfjj3yTe08UtvedwS885XHjcB/h/J+y/d+6eVlqdWp+EiGQdJYixat0j9K64mtzGdfzJD+ffuj/O0UceyYMnzWFiRYbNsSMiY5ISxFjT+Bd6H/gquW+toI5JXN/1FSoOOZ3/OXkus2o0h5CIjBwliLGiq53eJ74DT32XzngO3+u+iLcP+AT/+NFDmD+lYrSjE5EspAQx2tyJv3Yfsd9dQ0lHhPt6P8iKSZ/jb08/jqtnaSyBiIweJYjR1LKZ2H1fomjdCtbHZ7Cs4hucdsb5/OjA2oyeGkRE9g1KEKPBHdbcQ3zF1eR0tvHt+CXMOecavrlwBjk5SgwiMjYoQYy05nr43T/AWw/wes6BXB3/DNdfcS5HqjlJRMYYJYiR4g6rfwEPfBXv7eLmgiu4OXYyy644WslBRMYkJYiR0LQB/veL8PajdE09hiu2X86LreO49YrFSg4iMmYpQaSTO6z6GTx0HXic5g//B+c+N49NrV1KDiIy5ilBpMv2d+H+v4O/PAGzP0TDR77FhfdE2NwS47YrFrNIyUFExjgliL0tHofnfwqPfB0sB864ic1zLuLinzzL5mYlBxHZdyhB7E3b3g5qDev/DPufBGd+l805tVx8yzNKDiKyz1GC2BvivfDsj+HRGyC3AM76Phx2GZtbOpUcRGSfpQSxpzq2w12XwHtPwZyPwpk3QcUUNjfHlBxEZJ+mBLEnOlvgjo/BpjVwzo/g0IvATMlBRDKCEsTu6mqHOy+C+hfhwp/DB04HYHNzjItueYYtSg4iso9TgtgdPZ1w78eDzujzf5o0Odz+N4s5YqaSg4jsu5Qg3q/eHlh+Bax7BM76HhzyMUDJQUQyT85oB7BPicfht5+DN34Hp34TDv8EoOQgIplJCSJV7vD7f4CX74WTroOjPwtAT2+cS3/6rJKDiGQcJYhUuMODX4VVt8LxXw4eoY1NHazb0so1p81TchCRjKIEkYrH/gOe+SEc9Tn4yNcGFEWiMQBmV5eORmQiImmjBLErT/5feOI/g/6GU2+EQbcCjUQ7AJhcVTQa0YmIpE1aE4SZnWpmb5rZOjO7Jkn5TDN71MzWmNnjZjYtoWyGmT1kZq+b2WtmNiudsSb17C3BpHuH/DWccdNOyQGgvimoQUyuVIIQkcyStgRhZrnAD4AlwHzgYjObP2i3bwG3u/sC4AbgxoSy24H/cvd5wGJgS7piTerFO+APX4EPnAHn3Aw5uUl32xSNUVmcT0mBrhgWkcySzhrEYmCdu7/j7l3A3cDZg/aZDzwaLj/WVx4mkjx3fxjA3VvdvT2NsQ70yq+CWVn3Pwk+tgxy84fcNRLtUO1BRDJSOhPEVGBDwnpduC3RS8D54fK5QLmZVQNzgSYz+7WZvWhm/xXWSAYws6VmttLMVjY0NOydqN9YAb9eCjOOgQvvgLzCYXevb4oxpap477y3iMgYks4EsXODPfig9auAE8zsReAEYCPQQzDC+/iw/EhgP+CTO72Y+y3uvsjdF9XW1u55xG8/Br+8HCYfCpfcAwUluzxENQgRyVTpTBB1wPSE9WlAfeIO7l7v7ue5+2HAP4XbouGxL4bNUz3Ab4HD0xgrrH8a7r4EaubCpcuhsHyXh8S6e9ne3q0EISIZKZ0J4nlgjpnNNrMC4CLg/sQdzKzGzPpiuBZYlnDsODPrqxZ8BHgtbZFufAF+8ddQMRU+/lsoSW3AW98YiMmVamISkcyTtgQR/vK/EngQeB24191fNbMbzOyscLcTgTfN7C1gIvDv4bG9BM1Lj5rZywTNVT9JS6CN78Ad5wVJ4fL7oSz1pqpIk8ZAiEjmSuu1me6+AlgxaNt1CcvLgeVDHPswsCCd8QFQOR0WXAhHfw4qpryvQ1WDEJFMpov3c/NhyTd369D+UdTqgxCRDKSpNvZAfTTG+NICivKTD6ITEdmXKUHsgU3RGJMqVHsQkcykBLEH6ps6mKIOahHJUEoQeyASjamDWkQylhLEbmrv6iHa0c0kdVCLSIZSgthNfZe4qolJRDKVEsRuijRpDISIZDYliN2kMRAikumUIHZTXxOT+iBEJFMpQeymSLSDmrICCvM0SE5EMpMSxG6KRGOqPYhIRkspQZjZr8zs9ISpubNepEljIEQks6V6wr8ZuARYa2bfMLMPpDGmfUJ9tIMpqkGISAZLKUG4+yPufinBXd3eBR42s6fM7FNmlp/OAMei1s4eWmI9TFINQkQyWMpNRmZWTXBf6L8FXgS+S5AwHk5LZGPYpvASVw2SE5FMltL9IMzs18AHgJ8DZ7p7JCy6x8xWpiu4sapeg+REJAukesOg77v7H5MVuPuivRjPPmFT/53kVIMQkcyVahPTPDOr6lsxs3Fm9vk0xTTm1Uc7MIOJuheEiGSwVBPEp929qW/F3bcDn05PSGNfpClGTVkhBXm66ldEMleqZ7gcM7O+FTPLBQrSE9LYF2mO6RJXEcl4qSaIB4F7zewkM/sIcBfwQPrCGtsiTR0aRS0iGS/VTuqrgc8AnwMMeAj4abqCGusi0RjHHlAz2mGIiKRVSgnC3eMEo6lvTm84Y19LrJvWzh6NgRCRjJfqOIg5wI3AfKD/zOju+6UprjFrxzTfGgMhIpkt1T6InxHUHnqADwO3EwyaG5aZnWpmb5rZOjO7Jkn5TDN71MzWmNnjZjZtUHmFmW00s++nGGfa1TeFo6jVByEiGS7VBFHs7o8C5u7r3f3rwEeGOyC80ukHwBKCmsfFZjZ/0G7fAnosmdIAABMnSURBVG539wXADQS1lET/CvwpxRhHRF8NYnKVahAiktlSTRCxcKrvtWZ2pZmdC0zYxTGLgXXu/o67dwF3A2cP2mc+8Gi4/FhiuZkdAUwk6BAfMyLRGGYwobxwtEMREUmrVBPEl4AS4O+BI4DLgMt3ccxUYEPCel24LdFLwPnh8rlAuZlVh8no28BXhnsDM1tqZivNbGVDQ0NKH2RPRZo6mFBeSH6uBsmJSGbb5VkubCq6wN1b3b3O3T/l7ue7+zO7OjTJNh+0fhVwgpm9CJwAbCTo5/g8sMLdNzAMd7/F3Re5+6La2tpdfZS9IhLVjYJEJDvs8iomd+81syPMzNx98Al+OHXA9IT1aUD9oNeuB84DMLMy4Hx3j5rZMcDx4XxPZUCBmbW6+04d3SMtEu1g7sTy0Q5DRCTtUh0o9yJwn5n9Emjr2+juvx7mmOeBOWY2m6BmcBHBXen6mVkN0BiOs7gWWBa+7qUJ+3wSWDQWkoO7E4nGOGHurrpfRET2fakmiPHANgZeueTAkAnC3XvM7EqCaTpygWXu/qqZ3QCsdPf7gROBG83MgSeAL7z/jzBymjt6aO/q1SA5EckKqY6k/tTuvLi7rwBWDNp2XcLycmD5Ll7jVuDW3Xn/vS3SHIyB0DxMIpINUh1J/TN27mDG3a/Y6xGNYRHdSU5EskiqTUy/S1guIrgktX6IfTNWve5FLSJZJNUmpl8lrpvZXcAjaYloDNsUjZFjUFumQXIikvl2d7TXHGDG3gxkX1DfFGNiRRF5GiQnIlkg1T6IFgb2QWwiuEdEVolEO5isDmoRyRKpNjFpZBhBE9O8yRWjHYaIyIhIqa3EzM41s8qE9SozOyd9YY097k69ahAikkVSbUy/3t2jfSvu3gRcn56Qxqam9m5i3XFN8y0iWSPVBJFsv1Qvkc0IffeB0I2CRCRbpJogVprZd8xsfzPbz8z+L7AqnYGNNZGoRlGLSHZJNUH8HdAF3APcC3QwxudN2tvq+2oQamISkSyR6lVMbcCoz6Y6mjZFO8jLMWo0SE5EskSqVzE9bGZVCevjzOzB9IU19kTCQXK5OcnugyQiknlSbWKqCa9cAsDdt7Pre1JnFF3iKiLZJtUEETez/qk1zGwWSWZ3zWSbojFd4ioiWSXVS1X/CXjSzP4Urn8IWJqekMaevjvJnXKQahAikj1S7aR+wMwWESSF1cB9BFcyZYXGti46e+JqYhKRrJLqZH1/C3wRmEaQII4GnmbgLUgzVt8gOd0oSESySap9EF8EjgTWu/uHgcOAhrRFNcbsSBCqQYhI9kg1QcTcPQZgZoXu/gZwYPrCGlv6RlFP1p3kRCSLpNpJXReOg/gt8LCZbSeLbjkaicbIzzVqSjVITkSyR6qd1OeGi183s8eASuCBtEU1xkSaOphYUUSOBsmJSBZ53zOyuvufdr1XZqmPxpiiDmoRyTK6uXIKgkFy6n8QkeyiBLEL8bizKRrTNN8iknXSmiDM7FQze9PM1pnZTrPBmtlMM3vUzNaY2eNmNi3cvtDMnjazV8OyC9MZ53C2tXXR1RtXE5OIZJ20JQgzywV+ACwB5gMXm9n8Qbt9C7jd3RcANwA3htvbgU+4+0HAqcBNibPJjqT+S1xVgxCRLJPOGsRiYJ27v+PuXcDdwNmD9pkPPBouP9ZX7u5vufvacLke2ALUpjHWIWkUtYhkq3QmiKnAhoT1unBbopeA88Plc4FyM6tO3MHMFgMFwNuD38DMlprZSjNb2dCQnoHdkSYNkhOR7JTOBJFs0MDgKcKvAk4wsxeBE4CNQE//C5hNBn4OfMrd4zu9mPst7r7I3RfV1qanghGJxijIzaG6tCAtry8iMla973EQ70MdMD1hfRqDRl+HzUfnAZhZGXC+u0fD9Qrg98A/u/szaYxzWJHwCiYzDZITkeySzhrE88AcM5ttZgXARcD9iTuYWY2Z9cVwLbAs3F4A/IagA/uXaYxxlyK6k5yIZKm0JQh37wGuBB4EXgfudfdXzewGMzsr3O1E4E0zewuYCPx7uP0CgpsSfdLMVoePhemKdTj1TTGm6E5yIpKF0tnEhLuvAFYM2nZdwvJyYHmS4+4A7khnbKmIx53NzTHVIEQkK2kk9TC2tnbSE3clCBHJSkoQw6jXGAgRyWJKEMPYpBsFiUgWU4IYRn2TahAikr2UIIYRiXZQmJfDuJL80Q5FRGTEKUEMIxINLnHVIDkRyUZKEMOIRGNMqlD/g4hkJyWIYUSaOtRBLSJZSwliCL1xZ3NLp24UJCJZSwliCA0tnfTGXbcaFZGspQQxhPpwDMQUNTGJSJZSghjCJo2iFpEspwQxhPom3YtaRLKbEsQQItEYxfm5VBZrkJyIZCcliCFsisaYXKU7yYlI9lKCGEK97iQnIllOCWIIkaaYOqhFJKspQSTR0xtnS0uMKapBiEgWU4JIYktLJ3GHSapBiEgWU4JIIqIbBYmIKEEkEwkHyWkeJhHJZkoQSUT67iSnGoSIZDEliCTqox2UFuRSXpg32qGIiIwaJYgkIk0xJutOciKS5ZQgkog0xzRITkSyXloThJmdamZvmtk6M7smSflMM3vUzNaY2eNmNi2h7HIzWxs+Lk9nnINFmjSKWkQkbQnCzHKBHwBLgPnAxWY2f9Bu3wJud/cFwA3AjeGx44HrgaOAxcD1ZjYuXbEm6uqJ09DaqVHUIpL10lmDWAysc/d33L0LuBs4e9A+84FHw+XHEso/Cjzs7o3uvh14GDg1jbH229ISw103ChIRSWeCmApsSFivC7clegk4P1w+Fyg3s+oUj8XMlprZSjNb2dDQsFeC7hsDoVHUIpLt0pkgkl0C5IPWrwJOMLMXgROAjUBPisfi7re4+yJ3X1RbW7un8QI7bhSkeZhEJNul80L/OmB6wvo0oD5xB3evB84DMLMy4Hx3j5pZHXDioGMfT2Os/fpvNVqlGoSIZLd01iCeB+aY2WwzKwAuAu5P3MHMasysL4ZrgWXh8oPAKWY2LuycPiXclnaRaIzywjzKNEhORLJc2hKEu/cAVxKc2F8H7nX3V83sBjM7K9ztROBNM3sLmAj8e3hsI/CvBEnmeeCGcFva1Td1aIoNERHS28SEu68AVgzadl3C8nJg+RDHLmNHjWLEbGrWjYJEREAjqXdS36RR1CIioAQxQGdPL1s1SE5EBFCCGGBLcyegab5FREAJYoC+MRBqYhIRUYIYoG8UtZqYRESUIAbYkSBUgxARUYJIEIl2UFGUR6kGyYmIKEEkqm+KMUVTbIiIAEoQA2xq1o2CRET6KEEkiDTFNM23iEhICSIU6+5lW1uXpvkWEQkpQYQ2N2uabxGRREoQofqmIEGoBiEiElCCCEWiwSjqSUoQIiKAEkQ/jaIWERlICSIUiXYwriSf4oLc0Q5FRGRMUIII6RJXEZGBlCBCkWhMHdQiIgmUIEKRqO5FLSKSSAkC6OjqZXt7tzqoRUQSKEGw4xJXzcMkIrKDEgSwSZe4iojsRAkCqNeNgkREdqIEAUSaNIpaRGSwtCYIMzvVzN40s3Vmdk2S8hlm9piZvWhma8zstHB7vpndZmYvm9nrZnZtOuOMNMeoLi2gKF+D5ERE+qQtQZhZLvADYAkwH7jYzOYP2u2fgXvd/TDgIuCH4fa/Bgrd/RDgCOAzZjYrXbFGmjpUexARGSSdNYjFwDp3f8fdu4C7gbMH7eNARbhcCdQnbC81szygGOgCmtMVaCQaUwe1iMgg6UwQU4ENCet14bZEXwcuM7M6YAXwd+H25UAbEAHeA77l7o3pCjQSjTFFg+RERAZIZ4KwJNt80PrFwK3uPg04Dfi5meUQ1D56gSnAbODLZrbfTm9gttTMVprZyoaGht0Ksr2rh2hHt5qYREQGSWeCqAOmJ6xPY0cTUp+/Ae4FcPengSKgBrgEeMDdu919C/BnYNHgN3D3W9x9kbsvqq2t3a0gY91xzjx0CodMrdyt40VEMlU6E8TzwBwzm21mBQSd0PcP2uc94CQAM5tHkCAawu0fsUApcDTwRjqCHF9awPcuPozj5+xeghERyVRpSxDu3gNcCTwIvE5wtdKrZnaDmZ0V7vZl4NNm9hJwF/BJd3eCq5/KgFcIEs3P3H1NumIVEZGdWXA+3vctWrTIV65cOdphiIjsU8xslbvv1IQPGkktIiJDUIIQEZGklCBERCQpJQgREUlKCUJERJJSghARkaQy5jJXM2sA1u/BS9QAW/dSOOmg+PaM4tszim/PjOX4Zrp70pHCGZMg9pSZrRzqWuCxQPHtGcW3ZxTfnhnr8Q1FTUwiIpKUEoSIiCSlBLHDLaMdwC4ovj2j+PaM4tszYz2+pNQHISIiSakGISIiSSlBiIhIUlmVIMzsVDN708zWmdk1ScoLzeyesPxZM5s1grFNN7PHzOx1M3vVzL6YZJ8TzSxqZqvDx3UjFV9CDO+a2cvh++80v3p4k6f/Dr/DNWZ2+AjGdmDCd7PazJrN7EuD9hnR79DMlpnZFjN7JWHbeDN72MzWhs/jhjj28nCftWZ2+QjG919m9kb47/cbM6sa4thh/xbSGN/XzWxjwr/haUMcO+z/9zTGd09CbO+a2eohjk3797fH3D0rHkAu8DawH1AAvATMH7TP54EfhcsXAfeMYHyTgcPD5XLgrSTxnQj8bpS/x3eBmmHKTwP+QHBP8qOBZ0fx33sTwSCgUfsOgQ8BhwOvJGz7T+CacPka4JtJjhsPvBM+jwuXx41QfKcAeeHyN5PFl8rfQhrj+zpwVQr//sP+f09XfIPKvw1cN1rf354+sqkGsRhY5+7vuHsXcDdw9qB9zgZuC5eXAyeZmY1EcO4ecfcXwuUWgrvwTR2J997LzgZu98AzQJWZTR6FOE4C3nb3PRldv8fc/QmgcdDmxL+z24Bzkhz6UeBhd2909+3Aw8CpIxGfuz/kwR0hAZ4huJ/8qBji+0tFKv/f99hw8YXnjgsI7pa5T8qmBDEV2JCwXsfOJ+D+fcL/IFGgekSiSxA2bR0GPJuk+Bgze8nM/mBmB41oYAEHHjKzVWa2NEl5Kt/zSLiIof9jjvZ3ONHdIxD8MAAmJNlnrHyPVxDUCJPZ1d9COl0ZNoEtG6KJbix8f8cDm9197RDlo/n9pSSbEkSymsDga3xT2SetzKwM+BXwJXdvHlT8AkGTyaHA94DfjmRsoWPd/XBgCfAFM/vQoPKx8B0WAGcBv0xSPBa+w1SMhe/xn4Ae4BdD7LKrv4V0uRnYH1gIRAiacQYb9e8PuJjhaw+j9f2lLJsSRB0wPWF9GlA/1D5mlgdUsnvV291iZvkEyeEX7v7rweXu3uzureHyCiDfzGpGKr7wfevD5y3Abwiq8olS+Z7TbQnwgrtvHlwwFr5DYHNfs1v4vCXJPqP6PYad4mcAl3rYYD5YCn8LaeHum929193jwE+GeN/R/v7ygPOAe4baZ7S+v/cjmxLE88AcM5sd/sK8CLh/0D73A31Xi3wM+ONQ/zn2trC98n+A1939O0PsM6mvT8TMFhP8+20bifjC9yw1s/K+ZYLOzFcG7XY/8InwaqajgWhfc8oIGvKX22h/h6HEv7PLgfuS7PMgcIqZjQubUE4Jt6WdmZ0KXA2c5e7tQ+yTyt9CuuJL7NM6d4j3TeX/ezr9FfCGu9clKxzN7+99Ge1e8pF8EFxh8xbB1Q3/FG67geA/AkARQbPEOuA5YL8RjO04girwGmB1+DgN+Czw2XCfK4FXCa7IeAb44Ah/f/uF7/1SGEffd5gYowE/CL/jl4FFIxxjCcEJvzJh26h9hwSJKgJ0E/yq/RuCfq1HgbXh8/hw30XATxOOvSL8W1wHfGoE41tH0H7f93fYd2XfFGDFcH8LIxTfz8O/rTUEJ/3Jg+ML13f6/z4S8YXbb+37m0vYd8S/vz19aKoNERFJKpuamERE5H1QghARkaSUIEREJCklCBERSUoJQkREklKCEBkDwllmfzfacYgkUoIQEZGklCBE3gczu8zMngvn8P+xmeWaWauZfdvMXjCzR82sNtx3oZk9k3BfhXHh9gPM7JFwwsAXzGz/8OXLzGx5eC+GX4zUTMIiQ1GCEEmRmc0DLiSYZG0h0AtcCpQSzP10OPAn4PrwkNuBq919AcHI377tvwB+4MGEgR8kGIkLwQy+XwLmE4y0PTbtH0pkGHmjHYDIPuQk4Ajg+fDHfTHBRHtxdkzKdgfwazOrBKrc/U/h9tuAX4bz70x1998AuHsMIHy95zycuye8C9ks4Mn0fyyR5JQgRFJnwG3ufu2AjWZfG7TfcPPXDNds1Jmw3Iv+f8ooUxOTSOoeBT5mZhOg/97SMwn+H30s3OcS4El3jwLbzez4cPvHgT95cI+POjM7J3yNQjMrGdFPIZIi/UIRSZG7v2Zm/0xwF7Acghk8vwC0AQeZ2SqCuxBeGB5yOfCjMAG8A3wq3P5x4MdmdkP4Gn89gh9DJGWazVVkD5lZq7uXjXYcInubmphERCQp1SBERCQp1SBERCQpJQgREUlKCUJERJJSghARkaSUIEREJKn/D6xWcw6E17f0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9xaRsbMM0QA"
      },
      "source": [
        "Saving and Loading a Network CNN\n",
        "-------------\n",
        "\n",
        "It is possible to save the configuration of a specific network model in a JSON file format. This will also allow a later, faster reloading of the model and its training, as in the example below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "m5RAM14aM0QD",
        "outputId": "1e05537a-ff3f-4cbf-994e-aabbfb918816"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "#Creatinon of of the model configuration in jsom format\n",
        "json_string = model.to_json()\n",
        "\n",
        "#model reconstruction from json format\n",
        "model = model_from_json(json_string)\n",
        "\n",
        "# Now let's compile, summarise and then train/fit the model.\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# let's reduce the number of epoch to 3, for a faster test of the checkpoint utility\n",
        "N_EPOCH = 3\n",
        "\n",
        "\n",
        "history = model.fit(input_X_train, output_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 1, 28, 20)         14020     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1, 28, 20)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 14, 50)         12550     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1, 14, 50)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 7, 25)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 175)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               88000     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 119,580\n",
            "Trainable params: 119,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/3\n",
            "48000/48000 [==============================] - 13s 276us/step - loss: 0.2543 - accuracy: 0.9197 - val_loss: 0.1065 - val_accuracy: 0.9663\n",
            "Epoch 2/3\n",
            "48000/48000 [==============================] - 13s 274us/step - loss: 0.0858 - accuracy: 0.9736 - val_loss: 0.0918 - val_accuracy: 0.9725\n",
            "Epoch 3/3\n",
            "48000/48000 [==============================] - 13s 263us/step - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.0756 - val_accuracy: 0.9765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_ke9T2aM0QO"
      },
      "source": [
        "Checkpoints\n",
        "-------------\n",
        "\n",
        "Another important utility in Keras is the saving of the trained weights of the network at the end of the training, or at specific timesteps called checkpoints. This will permit, for example, (i) the continuation of the training at a later stage starting from the saved checkpoint weights, (ii) the later inspection of the network performance at the chosen checkpoints, (iii) the saving of the weights of the best version during the training, e.g. for a specified accuracy value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9hfpNu2M0QS"
      },
      "source": [
        "**Saving weights at the end of the training**\n",
        "\n",
        "The first example below shows how to save the weighst at the end of the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "L50zzireM0QV",
        "outputId": "6624fbdd-4d5d-411a-dc59-c0593b3f02bf"
      },
      "source": [
        "from keras.models import load_model \n",
        "\n",
        "#This saves the weights at the last epoch of the previous training session\n",
        "model.save('my_model.LeNet')\n",
        "print ('Weights saved for final epoch ', N_EPOCH)\n",
        "print ('Check that there is a weight file in your folder')\n",
        "\n",
        "#This loads the weight file 'my_model.LeNet'\n",
        "model = load_model('my_model.LeNet')\n",
        "print ('Loading of the saved weights and test using these trained weights')\n",
        "\n",
        "# let's check that the weighst loaded in this examples have kept the trained state of the network.\n",
        "score = model.evaluate(input_X_test, output_y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights saved for final epoch  3\n",
            "Check that there is a weight file in your folder\n",
            "Loading of the saved weights and test using these trained weights\n",
            "10000/10000 [==============================] - 1s 120us/step\n",
            "\n",
            "Test score/loss: 0.06308073911508545\n",
            "Test accuracy: 0.9793000221252441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHtYOoztM0Qc"
      },
      "source": [
        "**Regular checkpoint saving**\n",
        "\n",
        "This example shows how to save the weights at regular inverval checkpoints. The default value for the __ModelCheckpoint__ functiion is every 1 epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "Ph5G3908M0Qe",
        "outputId": "38b47808-6e18-46c6-aa0a-ab6b89516d5a"
      },
      "source": [
        "# additional checkpoint load code and temp directory definition\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model \n",
        "import os\n",
        "MODEL_DIR = \"./tmp\"\n",
        "\n",
        "# let's reduce the number of epoch to 3, for a faster test of the checkpoint utility\n",
        "N_EPOCH = 3\n",
        "\n",
        "\n",
        "# definition of checkpoint parameters file\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "checkpoint = ModelCheckpoint(filepath=os.path.join(MODEL_DIR, \"my_model-{epoch:02d}.LeNet\"))\n",
        "\n",
        "print ('Training with checkpoint at each epoch. Check that at the end of each epoch, there is a weight file in the tmp folder')\n",
        "model.fit(input_X_train, output_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=0.5, callbacks=[checkpoint])\n",
        "\n",
        "score = model.evaluate(input_X_test, output_y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Let's load the weights of the 2nd epoch, and check the scores \n",
        "model = load_model(os.path.join(MODEL_DIR,'my_model-02.LeNet'))\n",
        "print ('Weights loaded for epoch 2 .')\n",
        "print ('New test using these trained weights.')\n",
        "\n",
        "# let's check that the weights loaded in this examples have kept the trained state of the network.\n",
        "score = model.evaluate(input_X_test, output_y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score/loss:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with checkpoint at each epoch. Check that at the end of each epoch, there is a weight file in the tmp folder\n",
            "Train on 30000 samples, validate on 30000 samples\n",
            "Epoch 1/3\n",
            "30000/30000 [==============================] - 10s 341us/step - loss: 0.0506 - accuracy: 0.9839 - val_loss: 0.0590 - val_accuracy: 0.9811\n",
            "Epoch 2/3\n",
            "30000/30000 [==============================] - 11s 364us/step - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.0589 - val_accuracy: 0.9824\n",
            "Epoch 3/3\n",
            "30000/30000 [==============================] - 11s 377us/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
            "10000/10000 [==============================] - 1s 124us/step\n",
            "\n",
            "Test score/loss: 0.057427219665329904\n",
            "Test accuracy: 0.982699990272522\n",
            "Weights loaded for epoch 2 .\n",
            "New test using these trained weights.\n",
            "10000/10000 [==============================] - 1s 105us/step\n",
            "\n",
            "Test score/loss: 0.0567632404549513\n",
            "Test accuracy: 0.9824000000953674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcHg5iVJM0Ql"
      },
      "source": [
        "Using TensorBoard to Visualise CNN Performance\n",
        "-------------\n",
        "\n",
        "Keras provides a callback for saving the training and test metrics, as well as the activation histograms for the different layers in the model.\n",
        "\n",
        "The saved data can then be visualized with the TensorBoad launched at the command line:\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "_KlPXj_7M0Qm",
        "outputId": "133eafb8-5418-4ac5-c220-6597dd69ff8f"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "N_EPOCH = 20\n",
        "\n",
        "#keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
        "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
        "\n",
        "model.fit(input_X_train, output_y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=0.5, callbacks=[tensorboard])\n",
        "\n",
        "# Launch of TensorBoard to visualise the performance of the mdoel using the saved data\n",
        "\n",
        "\n",
        "# Launch tensorboard in colab:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs\n",
        "\n",
        "# or launch tensorboard if you're running the exercise in your computer\n",
        "#!tensorboard \"--logdir=./logs\" --host localhost --port 6006\n",
        "# Launch Chrome browser and go to localhost:6006 to view tensorboard\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 30000 samples\n",
            "Epoch 1/4\n",
            "30000/30000 [==============================] - 10s 328us/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0607 - val_accuracy: 0.9812\n",
            "Epoch 2/4\n",
            "30000/30000 [==============================] - 13s 447us/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.0601 - val_accuracy: 0.9814\n",
            "Epoch 3/4\n",
            "30000/30000 [==============================] - 10s 338us/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0726 - val_accuracy: 0.9785\n",
            "Epoch 4/4\n",
            "30000/30000 [==============================] - 10s 335us/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0617 - val_accuracy: 0.9824\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cangela/Library/Python/3.7/bin/tensorboard\", line 10, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/Users/cangela/Library/Python/3.7/lib/python/site-packages/tensorboard/main.py\", line 59, in run_main\n",
            "    default.get_plugins() + default.get_dynamic_plugins(),\n",
            "  File \"/Users/cangela/Library/Python/3.7/lib/python/site-packages/tensorboard/default.py\", line 110, in get_dynamic_plugins\n",
            "    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\n",
            "  File \"/Users/cangela/Library/Python/3.7/lib/python/site-packages/tensorboard/default.py\", line 110, in <listcomp>\n",
            "    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\n",
            "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2410, in load\n",
            "    self.require(*args, **kwargs)\n",
            "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2433, in require\n",
            "    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n",
            "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
            "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
            "pkg_resources.VersionConflict: (setuptools 40.8.0 (/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages), Requirement.parse('setuptools>=41.0.0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcqN9WwlM0Qv"
      },
      "source": [
        "Conclusions\n",
        "-------------\n",
        "\n",
        "We have learned to train our first, real __deep__ neural network, using the well known LeCun CNN for the MNIST dataset. Later we will explore the use of deeper networks and more complex dataset.\n",
        "\n",
        "**Copyright (c)** 2019 Angelo Cangelosi, MIT License. Code and examples adapted from Gulli & Pal (2017) Deep Learning with Kera. Punkt Publishing"
      ]
    }
  ]
}